using DataFrames;
using CSV;
using Plots;
using Flux;
using Statistics;
using Random;

function split_idxs(length, ratio)
    idx = randperm(length)
    train_idx = idx[1:round(Int, ratio * length)]
    test_idx = idx[round(Int, ratio * length):length]
    train_idx, test_idx
end

const train_idx, test_idx = split_idxs(891, 0.8)

function encode_string_one_hot(ğŸ::DataFrame, ğŸŒ::DataFrame, name::String)
    ğŸ« = unique(ğŸ[!, name])
    for ğŸŒ¸ in ğŸ«
        if !ismissing(ğŸŒ¸)
            ğŸ´ = name * "_" * string(ğŸŒ¸)
            ğŸŒ[!, ğŸ´] = (ğŸ[!, :Embarked] .== ğŸŒ¸)
            ğŸŒ[!, ğŸ´] = coalesce.(ğŸŒ[!, ğŸ´], false)
        end
    end
end

function rescalefield(ğŸ::DataFrame, ğŸ’::Symbol)
    ğŸ[!, ğŸ’] = coalesce.(
        ğŸ[!, ğŸ’], mean(
            skipmissing(ğŸ[!, ğŸ’])
        )
    )
    ğŸ_mean = mean(ğŸ[!, ğŸ’])
    ğŸ_std = std(ğŸ[!, ğŸ’])
    ğŸ[!, ğŸ’] = (ğŸ[!, ğŸ’] .- ğŸ_mean) ./ ğŸ_std
end

function tomatrix(ğŸ::DataFrame)::Matrix{Float32}
    ğŸ•´::Matrix{Float32} = Array{Float32}(undef, ncol(ğŸ), nrow(ğŸ))
    for Î¹ in 1:ncol(ğŸ)
        ğŸ•´[Î¹, :] = convert(Array{Float32}, ğŸ[!, Î¹])
    end
    ğŸ•´
end

function load_data(name::String)::Tuple{Matrix{Float32},Array{Float32}}
    df = CSV.read(name, DataFrame)

    ğŸš¢ = df[:, [:Age, :Fare, :SibSp, :Pclass, :Parch]]
    ğŸš¢[!, :Sex] = (df[:, :Sex] .== "male")
    encode_string_one_hot(df, ğŸš¢, "Embarked")
    encode_string_one_hot(df, ğŸš¢, "Cabin")

    rescalefield(ğŸš¢, :Age)
    rescalefield(ğŸš¢, :Fare)
    rescalefield(ğŸš¢, :SibSp)

    ğŸ£ = tomatrix(ğŸš¢)
    ğŸ“¤ = transpose(convert(Array{Float32}, df[!, :Survived]))

    ğŸ£, ğŸ“¤
end

##
function train_model(x, y, train_idx, test_idx, model)
    wts = Flux.params(model)

    optim = Flux.Optimise.ADAM()

    criterion(u, v) = Flux.Losses.binarycrossentropy(model(u), v)


    train_losses = []
    test_losses = []

    push!(train_losses, criterion(x[:, train_idx], y[:, train_idx]))
    push!(test_losses, criterion(x[:, test_idx], y[:, test_idx]))

    for epoch = 1:1000
        # compute gradient of the loss criterion
        grads = gradient(wts) do
            criterion(x[:, train_idx], y[:, train_idx])
        end

        push!(train_losses, criterion(x[:, train_idx], y[:, train_idx]))

        # update the model params
        Flux.update!(optim, wts, grads)

        # early stop
        new_test_loss = criterion(x[:, test_idx], y[:, test_idx])
        if (new_test_loss > test_losses[end]) && (epoch > 100)
            break
        end

        push!(test_losses, new_test_loss)
    end

    train_losses, test_losses
end
##

function plot_losses(train_losses, test_losses)
    plot(1:length(train_losses), train_losses, label="Train")
    plot!(1:length(test_losses), test_losses, label="Test")
    xlabel!("Iteration")
    ylabel!("Loss")
end

##
function main()
    x, y = load_data("dataset/titanic/train.csv")

    dld(n, m, d) = Chain(
        Dense(n, m, relu),
        Dropout(d),
        LayerNorm(m),
    )

    sm(n, d) = SkipConnection(Chain(
        dld(n, n, d),
        dld(n, n, d),
        dld(n, n, d),
    ), +)

    d_rate = 0.25

    ğŸ’ƒ = Chain(
        Dense(size(x)[1], 1024, relu),
        sm(1024, d_rate),
        dld(1024, 128, d_rate),
        sm(128, d_rate),
        dld(128, 32, d_rate),
        Dense(32, 1, sigmoid),
    )

    train_losses, test_losses = train_model(x, y, train_idx, test_idx, ğŸ’ƒ)

    accuracy(ğŸ, ğŸŒ) = sum(round.(ğŸ’ƒ(ğŸ)) .== ğŸŒ) / length(ğŸŒ)
    println("Final Accuracy = $(accuracy(x[:, test_idx], y[:, test_idx]))")

    plot_losses(train_losses, test_losses), ğŸ’ƒ
end

main()
##
